{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from distutils.dir_util import copy_tree, remove_tree\n",
    "\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef as MCC\n",
    "from sklearn.metrics import balanced_accuracy_score as BAS\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = './Alzheimers-OASIS'\n",
    "\n",
    "CLASSES = [ 'Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia',]\n",
    "\n",
    "IMG_SIZE = 248\n",
    "IMAGE_SIZE = [248, 248]\n",
    "DIM = (IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86437 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "ZOOM = [.99, 1.01]\n",
    "BRIGHT_RANGE = [0.8, 1.2]\n",
    "HORZ_FLIP = True\n",
    "FILL_MODE = \"constant\"\n",
    "DATA_FORMAT = \"channels_last\"\n",
    "\n",
    "work_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n",
    "\n",
    "train_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=9000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = train_data_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 248, 248, 3) (9000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = VGG19(input_shape=(248, 248, 3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg19_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg19_model = Sequential([\n",
    "        vgg19_model,\n",
    "        Dropout(0.5),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        BatchNormalization(),\n",
    "        Dense(4, activation='softmax')        \n",
    "    ], name = \"vgg19model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 512)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20465668 (78.07 MB)\n",
      "Trainable params: 438340 (1.67 MB)\n",
      "Non-trainable params: 20027328 (76.40 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),  \n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "        f1_score,\n",
    "]\n",
    "\n",
    "# CALLBACKS = rop_callback\n",
    "    \n",
    "custom_vgg19_model.compile(optimizer='rmsprop',\n",
    "                              loss=tf.losses.CategoricalCrossentropy(),\n",
    "                              metrics=METRICS)\n",
    "\n",
    "custom_vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "128/128 [==============================] - 1665s 13s/step - loss: 1.3818 - accuracy: 0.7516 - precision: 0.5048 - recall: 0.3306 - auc: 0.6982 - f1_score: 0.3979 - val_loss: 0.9753 - val_accuracy: 0.8132 - val_precision: 0.6753 - val_recall: 0.4868 - val_auc: 0.8824 - val_f1_score: 0.5647\n",
      "Epoch 2/3\n",
      "128/128 [==============================] - 1701s 13s/step - loss: 0.8381 - accuracy: 0.8451 - precision: 0.7261 - recall: 0.6111 - auc: 0.8807 - f1_score: 0.6621 - val_loss: 0.8096 - val_accuracy: 0.7899 - val_precision: 0.5819 - val_recall: 0.5674 - val_auc: 0.9033 - val_f1_score: 0.5746\n",
      "Epoch 3/3\n",
      "128/128 [==============================] - 1623s 13s/step - loss: 0.6370 - accuracy: 0.8797 - precision: 0.7765 - recall: 0.7286 - auc: 0.9288 - f1_score: 0.7517 - val_loss: 0.6053 - val_accuracy: 0.8757 - val_precision: 0.7710 - val_recall: 0.7153 - val_auc: 0.9449 - val_f1_score: 0.7414\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "history = custom_vgg19_model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=EPOCHS,steps_per_epoch=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 407s 7s/step - loss: 0.6112 - accuracy: 0.8696 - precision: 0.7552 - recall: 0.7078 - auc: 0.9437 - f1_score: 0.7291\n",
      "Testing Accuracy: 86.96%\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on the data\n",
    "\n",
    "#train_scores = model.evaluate(train_data, train_labels)\n",
    "#val_scores = model.evaluate(val_data, val_labels)\n",
    "test_scores = custom_vgg19_model.evaluate(test_data, test_labels)\n",
    "\n",
    "#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n",
    "#print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\n",
    "print(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 391s 7s/step\n"
     ]
    }
   ],
   "source": [
    "pred_labels = custom_vgg19_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Mild Dementia       0.67      0.99      0.80       979\n",
      " Moderate Dementia       0.00      0.00      0.00        97\n",
      "      Non Demented       0.98      0.48      0.64       724\n",
      "Very mild Dementia       0.00      0.00      0.00         0\n",
      "\n",
      "         micro avg       0.73      0.73      0.73      1800\n",
      "         macro avg       0.41      0.37      0.36      1800\n",
      "      weighted avg       0.76      0.73      0.69      1800\n",
      "       samples avg       0.73      0.73      0.73      1800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\logs\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\logs\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Print the classification report of the tested data\n",
    "\n",
    "#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n",
    "#similar to the test_labels\n",
    "def roundoff(arr):\n",
    "    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n",
    "    arr[np.argwhere(arr != arr.max())] = 0\n",
    "    arr[np.argwhere(arr == arr.max())] = 1\n",
    "    return arr\n",
    "\n",
    "for labels in pred_labels:\n",
    "    labels = roundoff(labels)\n",
    "\n",
    "print(classification_report(test_labels, pred_labels, target_names=CLASSES))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
